{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spider\n",
    "\n",
    "## Response por favor!!\n",
    "\n",
    "Antes de entrar a ejemplificar la implementación de un spider, revisemos el concepto de `Response`. \n",
    "\n",
    "**Selector VS Response**\n",
    "\n",
    "- `Response` tiene todas las herramientas que hemos aprendido con los `Selector`s\n",
    "  - Los métodos `xpath` y `css`  seguidos de los métodos `extract`y `extract_first`.\n",
    "- Los `Response` también mantienen un rastro de la url donde el código HTML fue cargado. \n",
    "- Los `Response` ayudan a moverse de un sitio a otro, así que se puede rastrear la web mientras se realizar el scraping.\n",
    "\n",
    "**Ejemplo de como funciona lo que ya hemos aprendido con `xpath` y `css`.**\n",
    "\n",
    "- El método `xpath`funciona con en un `Selector`\n",
    "```python\n",
    "response.xpath('//div/span/[@class=\"bio\"]')\n",
    "```\n",
    "- El método `css`funciona como en un `Selector`\n",
    "```python\n",
    "response.css('div > span.bio')\n",
    "```\n",
    "- El encadenamiento funciona como en un Selector\n",
    "```python\n",
    "response.xpath('//div').css('span.bio')\n",
    "```\n",
    "- La extracción de datos funciona como en un Selector\n",
    "```python\n",
    "response.xpath('//div').class('span.bio').extract()\n",
    "response.xpath('//div').class('span.bio').extract_first()\n",
    "```\n",
    "- Las `response`mantiene el rastro de las URL con la variable url response\n",
    "```python\n",
    "response.url\n",
    "```\n",
    "- La `response` nos permite \"seguir\" un nuevo link con el método `follow()`\n",
    "  \n",
    "```python\n",
    "# nex_url es la cadena de la ruta de la próxima url que queremos raspar\n",
    "response.follow(next_url)\n",
    "```\n",
    "\n",
    "## Implementación Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 15:58:55 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2024-12-20 15:58:55 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.13.5, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.13.0 | packaged by Anaconda, Inc. | (main, Oct  7 2024, 16:25:56) [Clang 14.0.6 ], pyOpenSSL 24.2.1 (OpenSSL 3.4.0 22 Oct 2024), cryptography 43.0.3, Platform macOS-15.1-arm64-arm-64bit-Mach-O\n",
      "2024-12-20 15:58:55 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2024-12-20 15:58:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2024-12-20 15:58:55 [scrapy.extensions.telnet] INFO: Telnet Password: 21013563afa1ba93\n",
      "2024-12-20 15:58:55 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2024-12-20 15:58:55 [scrapy.crawler] INFO: Overridden settings:\n",
      "{}\n",
      "2024-12-20 15:58:55 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2024-12-20 15:58:55 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2024-12-20 15:58:55 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2024-12-20 15:58:55 [scrapy.core.engine] INFO: Spider opened\n",
      "2024-12-20 15:58:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2024-12-20 15:58:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030\n",
      "2024-12-20 15:58:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ensenanza.html#oferta> (referer: None)\n",
      "2024-12-20 15:58:56 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2024-12-20 15:58:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 229,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 7457,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.394441,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2024, 12, 20, 21, 58, 56, 32826, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30260,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 110444544,\n",
      " 'memusage/startup': 110444544,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2024, 12, 20, 21, 58, 55, 638385, tzinfo=datetime.timezone.utc)}\n",
      "2024-12-20 15:58:56 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class UTMspider(scrapy.Spider):\n",
    "\tname = 'utm_spider'\n",
    "\n",
    "\tdef start_requests(self):\n",
    "\t\turls = ['https://www.utm.mx/ensenanza.html#oferta']\n",
    "\t\tfor url in urls:\n",
    "\t\t\tyield scrapy.Request(url = url, callback = self.parse)\n",
    "\n",
    "\tdef parse(self, response):\n",
    "\t\t# simple example: write out the html\n",
    "\t\thtml_file = 'utm_carrers.html'\n",
    "\t\twith open(html_file, 'wb') as fout:\n",
    "\t\t\tfout.write(response.body)\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(UTMspider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spider Versión 2.\n",
    "\n",
    "En la siguiente versión extraemos la lista de urls de las páginas de interes. En esta ocasión en el método `parse` utilizamos un `response.css` para obener los valores de los atributos `href` de las etiquetas `a` de interes.\n",
    "\n",
    "Si revisamos el resultado del archivo `UTM_links.csv` podemos observar que hemos recuperado 30 urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 16:08:36 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2024-12-20 16:08:36 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.13.5, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.13.0 | packaged by Anaconda, Inc. | (main, Oct  7 2024, 16:25:56) [Clang 14.0.6 ], pyOpenSSL 24.2.1 (OpenSSL 3.4.0 22 Oct 2024), cryptography 43.0.3, Platform macOS-15.1-arm64-arm-64bit-Mach-O\n",
      "2024-12-20 16:08:36 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2024-12-20 16:08:36 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2024-12-20 16:08:36 [scrapy.extensions.telnet] INFO: Telnet Password: 220b3ea71c7b089a\n",
      "2024-12-20 16:08:36 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2024-12-20 16:08:36 [scrapy.crawler] INFO: Overridden settings:\n",
      "{}\n",
      "2024-12-20 16:08:36 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2024-12-20 16:08:36 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2024-12-20 16:08:36 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2024-12-20 16:08:36 [scrapy.core.engine] INFO: Spider opened\n",
      "2024-12-20 16:08:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2024-12-20 16:08:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032\n",
      "2024-12-20 16:08:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ensenanza.html#oferta> (referer: None)\n",
      "2024-12-20 16:08:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2024-12-20 16:08:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 229,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 7457,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.312328,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2024, 12, 20, 22, 8, 36, 722293, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30260,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 109887488,\n",
      " 'memusage/startup': 109887488,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2024, 12, 20, 22, 8, 36, 409965, tzinfo=datetime.timezone.utc)}\n",
      "2024-12-20 16:08:36 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ing_computacion.html', 'ing_electronica.html', 'ing_diseno.html', 'lic_ciencias_empresariales.html', 'lic_mate_aplicadas.html', 'ing_alimentos.html', 'ing_industrial.html', 'http://virtual.utm.mx/licenciatura_estudios_mexicanos.html', 'ing_mecatronica.html', 'ing_fisica_aplicada.html', 'ing_mecanica_automotriz.html', 'ing_civil.html', 'ing_quimica_procesos_sostenible.html', 'm_admon_negocios.html', 'mc_materiales.html', 'm_prod_nat_alim.html', 'm_diseno_muebles.html', 'm_electronica_sia.html', 'm_ing_sw.html', 'https://www.utm.mx/m_inteligencia_artificial.html', 'm_medios_interactivos.html', 'm_modelacion_matematica.html', 'm_robotica.html', 'm_tec_avanz-manuf.html', ' http://virtual.utm.mx/maestria_ciencia_datos.html', 'https://www.utm.mx/dr_prod_nat_alim.html', 'dr_electronica_sia.html', 'https://www.utm.mx/dr_inteligencia_artificial.html', 'dr_modelacion_matematica.html', 'dr_robotica.html']\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class UTMspider(scrapy.Spider):\n",
    "\tname = 'utm_spider'\n",
    "\n",
    "\tdef start_requests(self):\n",
    "\t\turls = ['https://www.utm.mx/ensenanza.html#oferta']\n",
    "\t\tfor url in urls:\n",
    "\t\t\tyield scrapy.Request(url = url, callback = self.parse)\n",
    "\t\t\t\n",
    "\tdef parse(self, response):\n",
    "\t\tlinks = response.css('div#expandir div.fijo:nth-of-type(1) a::attr(href)').extract()\n",
    "\t\tfilepath = 'UTM_links.csv'\n",
    "\t\twith open( filepath, 'w') as f:\n",
    "\t\t\tf.write('\\n'.join(link for link in links))\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(UTMspider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spider versión 3\n",
    "\n",
    "Realmente el objetivo del scraping es obtener datos y no solo las urls, por que necesimos construir una nueva versión que nos permita realizar el raspado de estas urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 20:28:14 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2024-12-22 20:28:14 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.13.5, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.11.0, Python 3.13.0 | packaged by Anaconda, Inc. | (main, Oct  7 2024, 16:25:56) [Clang 14.0.6 ], pyOpenSSL 24.2.1 (OpenSSL 3.4.0 22 Oct 2024), cryptography 43.0.3, Platform macOS-15.1-arm64-arm-64bit-Mach-O\n",
      "2024-12-22 20:28:14 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2024-12-22 20:28:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2024-12-22 20:28:14 [scrapy.extensions.telnet] INFO: Telnet Password: 02e6a709c4428a6e\n",
      "2024-12-22 20:28:14 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2024-12-22 20:28:14 [scrapy.crawler] INFO: Overridden settings:\n",
      "{}\n",
      "2024-12-22 20:28:14 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2024-12-22 20:28:14 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2024-12-22 20:28:14 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] INFO: Spider opened\n",
      "2024-12-22 20:28:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2024-12-22 20:28:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6038\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ensenanza.html#oferta> (referer: None)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/dr_robotica.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/m_medios_interactivos.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://virtual.utm.mx/maestria_ciencia_datos.html> (referer: None)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/m_robotica.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/m_inteligencia_artificial.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/dr_inteligencia_artificial.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/m_modelacion_matematica.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/dr_modelacion_matematica.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/m_tec_avanz-manuf.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/dr_prod_nat_alim.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/dr_electronica_sia.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/m_diseno_muebles.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/m_ing_sw.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/m_electronica_sia.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://virtual.utm.mx/licenciatura_estudios_mexicanos.html> (referer: None)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ing_quimica_procesos_sostenible.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ing_civil.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/mc_materiales.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/m_admon_negocios.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/m_prod_nat_alim.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ing_mecanica_automotriz.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ing_fisica_aplicada.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ing_industrial.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ing_mecatronica.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ing_alimentos.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/lic_mate_aplicadas.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ing_diseno.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ing_electronica.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/lic_ciencias_empresariales.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.utm.mx/ing_computacion.html> (referer: https://www.utm.mx/ensenanza.html)\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2024-12-22 20:28:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 8606,\n",
      " 'downloader/request_count': 31,\n",
      " 'downloader/request_method_count/GET': 31,\n",
      " 'downloader/response_bytes': 486400,\n",
      " 'downloader/response_count': 31,\n",
      " 'downloader/response_status_count/200': 31,\n",
      " 'elapsed_time_seconds': 0.541723,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2024, 12, 23, 2, 28, 14, 733989, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 2118311,\n",
      " 'httpcompression/response_count': 31,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/DEBUG': 32,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 109510656,\n",
      " 'memusage/startup': 109510656,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 31,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 31,\n",
      " 'scheduler/dequeued/memory': 31,\n",
      " 'scheduler/enqueued': 31,\n",
      " 'scheduler/enqueued/memory': 31,\n",
      " 'start_time': datetime.datetime(2024, 12, 23, 2, 28, 14, 192266, tzinfo=datetime.timezone.utc)}\n",
      "2024-12-22 20:28:14 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['INGENIERÍA QUÍMICA EN PROCESOS SOSTENIBLES'], ['INGENIERÍA CIVIL'], [], [], [], ['INGENIERÍA MECÁNICA AUTOMOTRIZ'], ['INGENIERÍA \\r\\n              EN FÍSICA APLICADA'], ['INGENIERÍA INDUSTRIAL'], ['INGENIERÍA \\r\\n              EN MECATRÓNICA'], ['INGENIERÍA EN ALIMENTOS'], ['LICENCIATURA \\n              EN MATEMÁTICAS APLICADAS'], ['INGENIERÍA \\n              EN DISEÑO'], ['INGENIERÍA \\r\\n              EN ELECTRÓNICA'], ['LICENCIATURA \\r\\n              EN CIENCIAS EMPRESARIALES'], ['INGENIERÍA \\r\\n              EN COMPUTACIÓN']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method CrawlerRunner.stop of <scrapy.crawler.CrawlerProcess object at 0x10964b770>>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class UTMspider(scrapy.Spider):\n",
    "\tname = 'utm_spider'\n",
    "\n",
    "\tdef start_requests(self):\n",
    "\t\turls = ['https://www.utm.mx/ensenanza.html#oferta']\n",
    "\t\tfor url in urls:\n",
    "\t\t\tyield scrapy.Request(url = url, callback = self.parse_front)\n",
    "\t\t\t\n",
    "\tdef parse_front(self, response):\n",
    "\t\tlinks = response.css('div#expandir div.fijo:nth-of-type(1) a::attr(href)').extract()\n",
    "\t\tfor link in links:\n",
    "\t\t\tif \"http\" not in link:\n",
    "\t\t\t\tlink = \"https://www.utm.mx/\" + link\n",
    "\t\t\tyield response.follow(url = link, callback = self.parse_pages)\n",
    "\t\t\t\n",
    "\tdef parse_pages(self, response):\n",
    "\t\tcr_title = response.xpath('//div[@class=\"Titulo\"]/text()').extract()\n",
    "\t\tutm.append(cr_title)\n",
    "\t\t\n",
    "\n",
    "utm = list()\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(UTMspider)\n",
    "process.start()\n",
    " \n",
    "print(utm)\n",
    "\n",
    "process.stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcd-projectsI2025a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
